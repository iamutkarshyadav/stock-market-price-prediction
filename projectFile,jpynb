#import the libraries 
import math
import pandas_datareader as web
import numpy as np 
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential 
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

!pip install --upgrade pandas-datareader

#get the number of the rows and columns in the data set 

df.shape

#visualize the closing price history 
plt.figure(figsize =(16,8))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date', fontsize = 18)
plt.ylabel('Close Price USD ($)', fontsize = 18)
plt.show()

 #create new data frame 
data = df.filter(['Close'])
#convert the dataframe to numpy array 
dataset = data.values
#get the number of rows to train the model 
tarining_data_len = math.ceil(len(dataset)* .8)
tarining_data_len

#scale the data 
scaler = MinMaxScaler(feature_range = (0,1))
scaled_data = scaler.fit_transform(dataset)
scaled_data
 #create the training dataset 
#create the scaled training dataset
train_data = scaled_data[0:tarining_data_len, :]
#splits data into x_train and y_train data sets 
x_train = []
y_train = []

for i in range (60, len(train_data)):
  x_train.append(train_data[i-60:i, 0])
  y_train.append(train_data[i, 0])
  if i<= 60:
     print(x_train)
     print(y_train)
     print()
     
     #convert the x_train and y_train to numpy arrays 
x_train, y_train = np.array(x_train), np.array(y_train)

#reshape data 
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_train.shape

#build the LSMT Model
model = Sequential()
model.add(LSTM(50, return_sequences = True, input_shape = (x_train.shape [1], 1)))
model.add(LSTM(50, return_sequences = False))
model.add(Dense(25))
model.add(Dense(1))

#compile the model 
model.compile(optimizer = 'adam', loss = 'mean_squared_error')

#train the model 
model.fit(x_train, y_train, batch_size = 1, epochs = 1)

#create the testing dataset
#creaye a new array containg scales values  from index 1543 t[ 2003] 
test_data = scaled_data[tarining_data_len -60: , :]
#create the data sets for both axis 
x_test = []
y_test = dataset[tarining_data_len: , :]
for i in range (60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])
    
    #convert the data into a numpy array 
x_test = np.array(x_test )

#reshape the data 
x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))

#get the model predicted values 
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#get root mean squared error 
rmse = np.sqrt(np.mean(predictions - y_test)**2)
rmse

#plot the data 
train = data[:tarining_data_len]
valid = data[tarining_data_len:]
valid['predictions'] = predictions 

#graph 
plt.figure(figsize = (16,8))
plt.title('Model ')
plt.xlabel('Date', fontsize = 18)
plt.ylabel('Close Price USD ($)', fontsize = 18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'predictions']])
plt.legend(['Train', 'Val', 'predictions'], loc = 'lower right')
plt.show()

#show the valid and predicted stock prices lol 
valid 

#get the quote 
apple_quote = web.DataReader('AAPL', data_source= 'yahoo', start = '2012-01-01', end = '2022-11-24')
#create new dataframe 
new_df = apple_quote.filter(['Close'])
#get tgh last 6o days closing price and convert the dataframe to an array 
last60days = new_df[-60:].values
#scale the dats betweenm 0 amd 1
last60daysscaled = scaler.transform(last60days)
#create an empty list 
x_test = []
#append the past 60 days 
x_test.append(last60daysscaled)
#convert the x data rp an numpy array 
x_test = np.array(x_test)
#reshaper the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
#get the predicted scaled price 
predprice = model.predict(x_test)
#undo scaling 
predprice = scaler.inverse_transform(predprice)
print(predprice)

#for predictions 

apple_quote2 = web.DataReader('AAPL', data_source= 'yahoo', start = '2012-01-01', end = '2022-11-30')
print(apple_quote2['Close'])
